---
title: Rationality
sidebar:
  order: 4
slug: artificial-intelligence/rationality
prev: true
next: true
---

### Perfect rationality

Assumes the agent knows everything. Always take the action that maximizes the utility. Might not be possible in all scenario.

### Bounded rationality

Assumes the agent has limited information. Uses approximate methods to perform tasks. Proposed by Herbert Simon in 1958.

## Rational action

Given the percept sequence, the action that maximizes the expected value of the performance measure. It is the best action, but not the optimal action.

## Omniscience

An agent exhibits omniscience when it knows the actual outcomes of its actions and can act accordingly. An ideal case, and not a practical goal. Rational agent and omniscient agent are independent.

It represents a hypothetical agent with complete knowledge of:
- The environment's true state
- All possible action outcomes
- The exact utility of each outcome

Real AI systems cannot achieve omniscience due to:
- Inherent uncertainty in complex environments
- Computational limitations
- Incomplete information

Omniscience serves as a useful theoretical benchmark against which to compare rational agents operating under uncertainty.
